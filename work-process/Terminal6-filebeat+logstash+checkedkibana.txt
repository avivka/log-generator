avivka@DESKTOP-48MKEI0:~$ kubectl logs kibana-5b78fbc78f-5qbgr
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:kibana@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:elasticsearch@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:xpack_main@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:graph@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:monitoring@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:spaces@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["security","warning"],"pid":1,"message":"Generating a random key for xpack.security.encryptionKey. To prevent sessions from being invalidated on restart, please set xpack.security.encryptionKey in kibana.yml"}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["security","warning"],"pid":1,"message":"Session cookies will be transmitted over insecure connections. This is not recommended."}
{"type":"log","@timestamp":"2020-08-22T21:06:16Z","tags":["status","plugin:security@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:searchprofiler@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:ml@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:tilemap@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:watcher@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:grokdebugger@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:dashboard_mode@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:logstash@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:beats_management@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:apm@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:tile_map@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:task_manager@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:maps@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:interpreter@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:canvas@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:license_management@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:cloud@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:index_management@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:console@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:console_extensions@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:notifications@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:index_lifecycle_management@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:infra@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:rollup@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:remote_clusters@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:cross_cluster_replication@6.8.12","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:translations@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:upgrade_assistant@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:uptime@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:oss_telemetry@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:metrics@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:17Z","tags":["status","plugin:timelion@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:20Z","tags":["status","plugin:elasticsearch@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["license","info","xpack"],"pid":1,"message":"Imported license information from Elasticsearch for the [data] cluster: mode: basic | status: active"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:xpack_main@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:graph@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:searchprofiler@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:ml@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:tilemap@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:watcher@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:grokdebugger@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:logstash@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:beats_management@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:index_management@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:index_lifecycle_management@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:rollup@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:remote_clusters@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:cross_cluster_replication@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["info","monitoring-ui","kibana-monitoring"],"pid":1,"message":"Monitoring status upload endpoint is not enabled in Elasticsearch:Monitoring stats collection is stopped"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:security@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["status","plugin:maps@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
{"type":"log","@timestamp":"2020-08-22T21:06:21Z","tags":["license","info","xpack"],"pid":1,"message":"Imported license information from Elasticsearch for the [monitoring] cluster: mode: basic | status: active"}
{"type":"log","@timestamp":"2020-08-22T21:06:37Z","tags":["reporting","browser-driver","warning"],"pid":1,"message":"Enabling the Chromium sandbox provides an additional layer of protection."}
{"type":"log","@timestamp":"2020-08-22T21:06:37Z","tags":["reporting","warning"],"pid":1,"message":"Generating a random key for xpack.reporting.encryptionKey. To prevent pending reports from failing on restart, please set xpack.reporting.encryptionKey in kibana.yml"}
{"type":"log","@timestamp":"2020-08-22T21:06:37Z","tags":["status","plugin:reporting@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
{"type":"log","@timestamp":"2020-08-22T21:06:38Z","tags":["listening","info"],"pid":1,"message":"Server running at http://0.0.0.0:5601"}
{"type":"log","@timestamp":"2020-08-22T21:06:38Z","tags":["status","plugin:spaces@6.8.12","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
avivka@DESKTOP-48MKEI0:~$ kubectl get svc
NAME                    TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
elasticsearch-cluster   ClusterIP      10.111.223.171   <none>        9300/TCP,9200/TCP   4m53s
kibana                  LoadBalancer   10.101.190.32    localhost     5061:30933/TCP      22m
kubernetes              ClusterIP      10.96.0.1        <none>        443/TCP             2d
avivka@DESKTOP-48MKEI0:~$ curl localhost:5061
curl: (52) Empty reply from server
avivka@DESKTOP-48MKEI0:~$ kubectl edit svc kibana
service/kibana edited
avivka@DESKTOP-48MKEI0:~$ kubectl describe svc kibana
Name:                     kibana
Namespace:                default
Labels:                   <none>
Annotations:              <none>
Selector:                 app=kibana
Type:                     LoadBalancer
IP:                       10.101.190.32
LoadBalancer Ingress:     localhost
Port:                     <unset>  5601/TCP
TargetPort:               5601/TCP
NodePort:                 <unset>  30933/TCP
Endpoints:                10.1.0.18:5601
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
avivka@DESKTOP-48MKEI0:~$ cd ./LogApp/
avivka@DESKTOP-48MKEI0:~/LogApp$ cd ..
avivka@DESKTOP-48MKEI0:~$ ls
LogApp  WaltyBE  WaltyBO  WaltyCrawlers  WaltyDevOps  WaltyFE  ubuntu_setup_env.sh
avivka@DESKTOP-48MKEI0:~$ cd ./LogApp/
avivka@DESKTOP-48MKEI0:~/LogApp$ ls
Dockerfile  controllers  date.log  log_generator.sh  work-process
avivka@DESKTOP-48MKEI0:~/LogApp$ cd controllers/
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ ls
elasticsearch-statefulset.yaml  elasticsearch-svc.yaml  elasticsearch_attempt.txt  kibana-deployment.yaml  kibana-svc-lb.yaml  log_generator-deployments.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ vim logstash-configmap.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f
elasticsearch-statefulset.yaml  elasticsearch_attempt.txt       kibana-svc-lb.yaml              logstash-configmap.yaml
elasticsearch-svc.yaml          kibana-deployment.yaml          log_generator-deployments.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f logstash-configmap.yaml
configmap/logstash-configmap created
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods --watch
NAME                                 READY   STATUS    RESTARTS   AGE
esnode-0                             1/1     Running   0          26m
kibana-5b78fbc78f-5qbgr              1/1     Running   0          19m
logapp-deployment-569dd8b478-mzjjv   1/1     Running   0          29h
^Cavivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get configmap
NAME                 DATA   AGE
es-config            2      124m
logstash-configmap   2      41s
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ vim logstash-deployment.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f
elasticsearch-statefulset.yaml  elasticsearch_attempt.txt       kibana-svc-lb.yaml              logstash-configmap.yaml
elasticsearch-svc.yaml          kibana-deployment.yaml          log_generator-deployments.yaml  logstash-deployment.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f logstash-deployment.yaml
deployment.apps/logstash created
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods --watch
NAME                                 READY   STATUS              RESTARTS   AGE
esnode-0                             1/1     Running             0          48m
kibana-5b78fbc78f-5qbgr              1/1     Running             0          41m
logapp-deployment-569dd8b478-mzjjv   1/1     Running             0          30h
logstash-54b9f64c7-vhstk             0/1     ContainerCreating   0          64s
^Cavivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe logstash-54b9f64c7-vhstk
error: the server doesn't have a resource type "logstash-54b9f64c7-vhstk"
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe pod logstash-54b9f64c7-vhstk
Name:           logstash-54b9f64c7-vhstk
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Sun, 23 Aug 2020 00:45:43 +0300
Labels:         app=logstash
                pod-template-hash=54b9f64c7
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  ReplicaSet/logstash-54b9f64c7
Containers:
  logstash-container:
    Container ID:
    Image:          docker.elastic.co/logstash/logstash:6.8.12
    Image ID:
    Port:           5044/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /usr/share/logstash/config from logstash-settings-config-volume (rw)
      /usr/share/logstash/pipeline from logstash-pipeline-config-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-284rj (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  logstash-settings-config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      logstash-configmap
    Optional:  false
  logstash-pipeline-config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      logstash-configmap
    Optional:  false
  default-token-284rj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-284rj
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                     Message
  ----    ------     ----  ----                     -------
  Normal  Scheduled  90s   default-scheduler        Successfully assigned default/logstash-54b9f64c7-vhstk to docker-desktop
  Normal  Pulling    89s   kubelet, docker-desktop  Pulling image "docker.elastic.co/logstash/logstash:6.8.12"
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ cd ..
avivka@DESKTOP-48MKEI0:~/LogApp$ cd controllers
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ ls
elasticsearch-statefulset.yaml  elasticsearch-svc.yaml  elasticsearch_attempt.txt  kibana-deployment.yaml  kibana-svc-lb.yaml  log_generator-deployments.yaml  logstash-configmap.yaml  logstash-deployment.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ vim logstash-svc.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f
elasticsearch-statefulset.yaml  elasticsearch_attempt.txt       kibana-svc-lb.yaml              logstash-configmap.yaml         logstash-svc.yaml
elasticsearch-svc.yaml          kibana-deployment.yaml          log_generator-deployments.yaml  logstash-deployment.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f logstash-svc.yaml
service/logstash-service created
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get svc
NAME                    TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
elasticsearch-cluster   ClusterIP      10.111.223.171   <none>        9300/TCP,9200/TCP   45m
kibana                  LoadBalancer   10.101.190.32    localhost     5601:30933/TCP      62m
kubernetes              ClusterIP      10.96.0.1        <none>        443/TCP             2d1h
logstash-service        ClusterIP      10.109.131.171   <none>        5044/TCP            4s
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods --watch
NAME                                 READY   STATUS    RESTARTS   AGE
esnode-0                             1/1     Running   0          51m
kibana-5b78fbc78f-5qbgr              1/1     Running   0          44m
logapp-deployment-569dd8b478-mzjjv   1/1     Running   0          30h
logstash-54b9f64c7-vhstk             1/1     Running   0          4m18s
^Cavivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs logstash-54b9f64c7-vhstk
Could not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console
[INFO ] 2020-08-22 21:48:06.034 [main] writabledirectory - Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
[INFO ] 2020-08-22 21:48:06.048 [main] writabledirectory - Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
[WARN ] 2020-08-22 21:48:06.779 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specified
[INFO ] 2020-08-22 21:48:06.790 [LogStash::Runner] runner - Starting Logstash {"logstash.version"=>"6.8.12"}
[INFO ] 2020-08-22 21:48:06.802 [LogStash::Runner] agent - No persistent UUID file found. Generating new UUID {:uuid=>"e6c5ce3f-4df5-4647-b069-6221d2f87d11", :path=>"/usr/share/logstash/data/uuid"}
[INFO ] 2020-08-22 21:48:30.848 [Converge PipelineAction::Create<main>] pipeline - Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[INFO ] 2020-08-22 21:48:34.609 [[main]-pipeline-manager] elasticsearch - Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch-cluster:9200/]}}
[WARN ] 2020-08-22 21:48:35.794 [[main]-pipeline-manager] elasticsearch - Restored connection to ES instance {:url=>"http://elasticsearch-cluster:9200/"}
[INFO ] 2020-08-22 21:48:36.456 [[main]-pipeline-manager] elasticsearch - ES Output version determined {:es_version=>6}
[WARN ] 2020-08-22 21:48:36.456 [[main]-pipeline-manager] elasticsearch - Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[INFO ] 2020-08-22 21:48:36.466 [[main]-pipeline-manager] elasticsearch - New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//elasticsearch-cluster:9200"]}
[INFO ] 2020-08-22 21:48:36.467 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Using default mapping template
[INFO ] 2020-08-22 21:48:36.470 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[INFO ] 2020-08-22 21:48:36.638 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Installing elasticsearch template to _template/logstash
[INFO ] 2020-08-22 21:48:37.004 [[main]-pipeline-manager] beats - Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[INFO ] 2020-08-22 21:48:37.026 [Converge PipelineAction::Create<main>] pipeline - Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x505397b0@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:173 sleep>"}
[INFO ] 2020-08-22 21:48:37.073 [Ruby-0-Thread-2: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/task.rb:22] agent - Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[INFO ] 2020-08-22 21:48:37.910 [Api Webserver] agent - Successfully started Logstash API endpoint {:port=>9600}
[INFO ] 2020-08-22 21:48:39.445 [[main]<beats] Server - Starting server on port: 5044
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ vim filebeat-configmap.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f filebeat-configmap.yaml
configmap/filebeat-config created
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ vim filebeat-deployment.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ mv filebeat-deployment.yaml filebeat-daemonset.yaml
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f filebeat-daemonset.yaml
error: error validating "filebeat-daemonset.yaml": error validating data: ValidationError(DaemonSet.spec): missing required field "selector" in io.k8s.api.apps.v1.DaemonSetSpec; if you choose to ignore these errors, turn validation off with --validate=false
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f filebeat-daemonset.yaml
daemonset.apps/filebeat created
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods --watch
NAME                                 READY   STATUS              RESTARTS   AGE
esnode-0                             1/1     Running             0          78m
filebeat-wg8zr                       0/1     ContainerCreating   0          7s
kibana-5b78fbc78f-5qbgr              1/1     Running             0          72m
logapp-deployment-569dd8b478-mzjjv   1/1     Running             0          30h
logstash-54b9f64c7-vhstk             1/1     Running             0          31m
^Cavivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe filebeat-wg8zr
error: the server doesn't have a resource type "filebeat-wg8zr"
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe pods filebeat-wg8zr
Name:           filebeat-wg8zr
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Sun, 23 Aug 2020 01:17:11 +0300
Labels:         app=filebeat
                controller-revision-hash=6478cb7857
                pod-template-generation=1
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  DaemonSet/filebeat
Containers:
  filebeat:
    Container ID:
    Image:         docker.elastic.co/beats/filebeat:6.8.12
    Image ID:
    Port:          <none>
    Host Port:     <none>
    Args:
      -c
      /etc/filebeat.yml
      -e
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Limits:
      memory:  200Mi
    Requests:
      cpu:        100m
      memory:     100Mi
    Environment:  <none>
    Mounts:
      /etc/filebeat.yml from config (ro,path="filebeat.yml")
      /usr/share/filebeat/data from data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-284rj (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      filebeat-config
    Optional:  false
  data:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/filebeat-data
    HostPathType:  DirectoryOrCreate
  default-token-284rj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-284rj
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/pid-pressure:NoSchedule
                 node.kubernetes.io/unreachable:NoExecute
                 node.kubernetes.io/unschedulable:NoSchedule
Events:
  Type     Reason       Age                From                     Message
  ----     ------       ----               ----                     -------
  Normal   Scheduled    51s                default-scheduler        Successfully assigned default/filebeat-wg8zr to docker-desktop
  Warning  FailedMount  18s (x7 over 50s)  kubelet, docker-desktop  MountVolume.SetUp failed for volume "config" : configmap "filebeat-config" not found
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get configma
error: the server doesn't have a resource type "configma"
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get configmap
NAME                 DATA   AGE
es-config            2      177m
logstash-configmap   2      53m
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl create -f filebeat-configmap.yaml
configmap/filebeat-config created
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe pods filebeat-wg8zr
Name:           filebeat-wg8zr
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Sun, 23 Aug 2020 01:17:11 +0300
Labels:         app=filebeat
                controller-revision-hash=6478cb7857
                pod-template-generation=1
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  DaemonSet/filebeat
Containers:
  filebeat:
    Container ID:
    Image:         docker.elastic.co/beats/filebeat:6.8.12
    Image ID:
    Port:          <none>
    Host Port:     <none>
    Args:
      -c
      /etc/filebeat.yml
      -e
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Limits:
      memory:  200Mi
    Requests:
      cpu:        100m
      memory:     100Mi
    Environment:  <none>
    Mounts:
      /etc/filebeat.yml from config (ro,path="filebeat.yml")
      /usr/share/filebeat/data from data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-284rj (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      filebeat-config
    Optional:  false
  data:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/filebeat-data
    HostPathType:  DirectoryOrCreate
  default-token-284rj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-284rj
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/pid-pressure:NoSchedule
                 node.kubernetes.io/unreachable:NoExecute
                 node.kubernetes.io/unschedulable:NoSchedule
Events:
  Type     Reason       Age                  From                     Message
  ----     ------       ----                 ----                     -------
  Normal   Scheduled    2m14s                default-scheduler        Successfully assigned default/filebeat-wg8zr to docker-desktop
  Warning  FailedMount  69s (x8 over 2m13s)  kubelet, docker-desktop  MountVolume.SetUp failed for volume "config" : configmap "filebeat-config" not found
  Warning  FailedMount  10s                  kubelet, docker-desktop  Unable to attach or mount volumes: unmounted volumes=[config], unattached volumes=[default-token-284rj config data]: timed out waiting for the condition
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe pods filebeat-wg8zr
Name:           filebeat-wg8zr
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Sun, 23 Aug 2020 01:17:11 +0300
Labels:         app=filebeat
                controller-revision-hash=6478cb7857
                pod-template-generation=1
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  DaemonSet/filebeat
Containers:
  filebeat:
    Container ID:
    Image:         docker.elastic.co/beats/filebeat:6.8.12
    Image ID:
    Port:          <none>
    Host Port:     <none>
    Args:
      -c
      /etc/filebeat.yml
      -e
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Limits:
      memory:  200Mi
    Requests:
      cpu:        100m
      memory:     100Mi
    Environment:  <none>
    Mounts:
      /etc/filebeat.yml from config (ro,path="filebeat.yml")
      /usr/share/filebeat/data from data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-284rj (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      filebeat-config
    Optional:  false
  data:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/filebeat-data
    HostPathType:  DirectoryOrCreate
  default-token-284rj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-284rj
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/pid-pressure:NoSchedule
                 node.kubernetes.io/unreachable:NoExecute
                 node.kubernetes.io/unschedulable:NoSchedule
Events:
  Type     Reason       Age                  From                     Message
  ----     ------       ----                 ----                     -------
  Normal   Scheduled    2m20s                default-scheduler        Successfully assigned default/filebeat-wg8zr to docker-desktop
  Warning  FailedMount  75s (x8 over 2m19s)  kubelet, docker-desktop  MountVolume.SetUp failed for volume "config" : configmap "filebeat-config" not found
  Warning  FailedMount  16s                  kubelet, docker-desktop  Unable to attach or mount volumes: unmounted volumes=[config], unattached volumes=[default-token-284rj config data]: timed out waiting for the condition
  Normal   Pulling      3s                   kubelet, docker-desktop  Pulling image "docker.elastic.co/beats/filebeat:6.8.12"
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl describe pods filebeat-wg8zr
Name:           filebeat-wg8zr
Namespace:      default
Priority:       0
Node:           docker-desktop/192.168.65.3
Start Time:     Sun, 23 Aug 2020 01:17:11 +0300
Labels:         app=filebeat
                controller-revision-hash=6478cb7857
                pod-template-generation=1
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  DaemonSet/filebeat
Containers:
  filebeat:
    Container ID:
    Image:         docker.elastic.co/beats/filebeat:6.8.12
    Image ID:
    Port:          <none>
    Host Port:     <none>
    Args:
      -c
      /etc/filebeat.yml
      -e
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Limits:
      memory:  200Mi
    Requests:
      cpu:        100m
      memory:     100Mi
    Environment:  <none>
    Mounts:
      /etc/filebeat.yml from config (ro,path="filebeat.yml")
      /usr/share/filebeat/data from data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-284rj (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      filebeat-config
    Optional:  false
  data:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/filebeat-data
    HostPathType:  DirectoryOrCreate
  default-token-284rj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-284rj
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/disk-pressure:NoSchedule
                 node.kubernetes.io/memory-pressure:NoSchedule
                 node.kubernetes.io/not-ready:NoExecute
                 node.kubernetes.io/pid-pressure:NoSchedule
                 node.kubernetes.io/unreachable:NoExecute
                 node.kubernetes.io/unschedulable:NoSchedule
Events:
  Type     Reason       Age                  From                     Message
  ----     ------       ----                 ----                     -------
  Normal   Scheduled    2m26s                default-scheduler        Successfully assigned default/filebeat-wg8zr to docker-desktop
  Warning  FailedMount  81s (x8 over 2m25s)  kubelet, docker-desktop  MountVolume.SetUp failed for volume "config" : configmap "filebeat-config" not found
  Warning  FailedMount  22s                  kubelet, docker-desktop  Unable to attach or mount volumes: unmounted volumes=[config], unattached volumes=[default-token-284rj config data]: timed out waiting for the condition
  Normal   Pulling      9s                   kubelet, docker-desktop  Pulling image "docker.elastic.co/beats/filebeat:6.8.12"
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ ^C

ubectl: command not found
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods
NAME                                 READY   STATUS             RESTARTS   AGE
esnode-0                             1/1     Running            0          85m
filebeat-wg8zr                       0/1     CrashLoopBackOff   5          7m1s
kibana-5b78fbc78f-5qbgr              1/1     Running            0          79m
logapp-deployment-569dd8b478-mzjjv   1/1     Running            0          30h
logstash-54b9f64c7-vhstk             1/1     Running            0          38m
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs pod filebeat-wg8zr
Error from server (NotFound): pods "pod" not found
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs filebeat-wg8zr
Exiting: error loading config file: open /etc/filebeat.yml: permission denied
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl apply -f filebeat-daemonset.yaml
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
daemonset.apps/filebeat configured
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods
NAME                                 READY   STATUS    RESTARTS   AGE
esnode-0                             1/1     Running   0          91m
filebeat-llrsm                       1/1     Running   0          4s
kibana-5b78fbc78f-5qbgr              1/1     Running   0          85m
logapp-deployment-569dd8b478-mzjjv   1/1     Running   0          30h
logstash-54b9f64c7-vhstk             1/1     Running   0          44m
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs filebeat-llrsm
2020-08-22T22:30:38.031Z        INFO    instance/beat.go:611    Home path: [/usr/share/filebeat] Config path: [/usr/share/filebeat] Data path: [/usr/share/filebeat/data] Logs path: [/usr/share/filebeat/logs]
2020-08-22T22:30:38.038Z        INFO    instance/beat.go:618    Beat UUID: d5e7672e-c6e1-450c-a189-5d61774e35a4
2020-08-22T22:30:38.039Z        INFO    [seccomp]       seccomp/seccomp.go:116  Syscall filter successfully installed
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:931    Beat info       {"system_info": {"beat": {"path": {"config": "/usr/share/filebeat", "data": "/usr/share/filebeat/data", "home": "/usr/share/filebeat", "logs": "/usr/share/filebeat/logs"}, "type": "filebeat", "uuid": "d5e7672e-c6e1-450c-a189-5d61774e35a4"}}}
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:940    Build info      {"system_info": {"build": {"commit": "fdb5036adbe45aa10a03882b2245578ad17c3615", "libbeat": "6.8.12", "time": "2020-08-12T06:26:46.000Z", "version": "6.8.12"}}}
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:943    Go runtime info {"system_info": {"go": {"os":"linux","arch":"amd64","max_procs":4,"version":"go1.10.8"}}}
2020-08-22T22:30:38.041Z        INFO    [beat]  instance/beat.go:947    Host info       {"system_info": {"host": {"architecture":"x86_64","boot_time":"2020-08-22T18:46:50Z","containerized":false,"name":"filebeat-llrsm","ip":["127.0.0.1/8","10.1.0.21/16"],"kernel_version":"4.19.104-microsoft-standard","mac":["86:2d:c8:4a:5d:d3"],"os":{"family":"redhat","platform":"centos","name":"CentOS Linux","version":"7 (Core)","major":7,"minor":8,"patch":2003,"codename":"Core"},"timezone":"UTC","timezone_offset_sec":0}}}
2020-08-22T22:30:38.041Z        INFO    [beat]  instance/beat.go:976    Process info    {"system_info": {"process": {"capabilities": {"inheritable":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"permitted":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"effective":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"bounding":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"ambient":null}, "cwd": "/usr/share/filebeat", "exe": "/usr/share/filebeat/filebeat", "name": "filebeat", "pid": 1, "ppid": 0, "seccomp": {"mode":"filter","no_new_privs":true}, "start_time": "2020-08-22T22:30:37.780Z"}}}
2020-08-22T22:30:38.041Z        INFO    instance/beat.go:280    Setup Beat: filebeat; Version: 6.8.12
2020-08-22T22:30:38.042Z        INFO    [publisher]     pipeline/module.go:110  Beat name: filebeat-llrsm
2020-08-22T22:30:38.043Z        INFO    [monitoring]    log/log.go:117  Starting metrics logging every 30s
2020-08-22T22:30:38.043Z        INFO    instance/beat.go:402    filebeat start running.
2020-08-22T22:30:38.043Z        INFO    registrar/registrar.go:97       No registry file found under: /usr/share/filebeat/data/registry. Creating a new registry file.
2020-08-22T22:30:38.047Z        INFO    registrar/registrar.go:134      Loading registrar data from /usr/share/filebeat/data/registry
2020-08-22T22:30:38.047Z        INFO    registrar/registrar.go:141      States Loaded from registrar: 0
2020-08-22T22:30:38.047Z        WARN    beater/filebeat.go:367  Filebeat is unable to load the Ingest Node pipelines for the configured modules because the Elasticsearch output is not configured/enabled. If you have already loaded the Ingest Node pipelines or are using Logstash pipelines, you can ignore this warning.
2020-08-22T22:30:38.047Z        INFO    crawler/crawler.go:72   Loading Inputs: 1
2020-08-22T22:30:38.047Z        INFO    log/input.go:148        Configured paths: [/logs/application.log]
2020-08-22T22:30:38.047Z        INFO    input/input.go:114      Starting input of type: log; ID: 2137414975019652560
2020-08-22T22:30:38.047Z        INFO    crawler/crawler.go:106  Loading and starting Inputs completed. Enabled inputs: 1
2020-08-22T22:30:38.047Z        INFO    log/harvester.go:255    Harvester started for file: /logs/application.log
2020-08-22T22:30:38.074Z        INFO    pipeline/output.go:95   Connecting to backoff(async(tcp://logstash-service:5044))
2020-08-22T22:30:38.076Z        INFO    pipeline/output.go:105  Connection to backoff(async(tcp://logstash-service:5044)) established
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs filebeat-llrsm
2020-08-22T22:30:38.031Z        INFO    instance/beat.go:611    Home path: [/usr/share/filebeat] Config path: [/usr/share/filebeat] Data path: [/usr/share/filebeat/data] Logs path: [/usr/share/filebeat/logs]
2020-08-22T22:30:38.038Z        INFO    instance/beat.go:618    Beat UUID: d5e7672e-c6e1-450c-a189-5d61774e35a4
2020-08-22T22:30:38.039Z        INFO    [seccomp]       seccomp/seccomp.go:116  Syscall filter successfully installed
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:931    Beat info       {"system_info": {"beat": {"path": {"config": "/usr/share/filebeat", "data": "/usr/share/filebeat/data", "home": "/usr/share/filebeat", "logs": "/usr/share/filebeat/logs"}, "type": "filebeat", "uuid": "d5e7672e-c6e1-450c-a189-5d61774e35a4"}}}
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:940    Build info      {"system_info": {"build": {"commit": "fdb5036adbe45aa10a03882b2245578ad17c3615", "libbeat": "6.8.12", "time": "2020-08-12T06:26:46.000Z", "version": "6.8.12"}}}
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:943    Go runtime info {"system_info": {"go": {"os":"linux","arch":"amd64","max_procs":4,"version":"go1.10.8"}}}
2020-08-22T22:30:38.041Z        INFO    [beat]  instance/beat.go:947    Host info       {"system_info": {"host": {"architecture":"x86_64","boot_time":"2020-08-22T18:46:50Z","containerized":false,"name":"filebeat-llrsm","ip":["127.0.0.1/8","10.1.0.21/16"],"kernel_version":"4.19.104-microsoft-standard","mac":["86:2d:c8:4a:5d:d3"],"os":{"family":"redhat","platform":"centos","name":"CentOS Linux","version":"7 (Core)","major":7,"minor":8,"patch":2003,"codename":"Core"},"timezone":"UTC","timezone_offset_sec":0}}}
2020-08-22T22:30:38.041Z        INFO    [beat]  instance/beat.go:976    Process info    {"system_info": {"process": {"capabilities": {"inheritable":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"permitted":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"effective":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"bounding":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"ambient":null}, "cwd": "/usr/share/filebeat", "exe": "/usr/share/filebeat/filebeat", "name": "filebeat", "pid": 1, "ppid": 0, "seccomp": {"mode":"filter","no_new_privs":true}, "start_time": "2020-08-22T22:30:37.780Z"}}}
2020-08-22T22:30:38.041Z        INFO    instance/beat.go:280    Setup Beat: filebeat; Version: 6.8.12
2020-08-22T22:30:38.042Z        INFO    [publisher]     pipeline/module.go:110  Beat name: filebeat-llrsm
2020-08-22T22:30:38.043Z        INFO    [monitoring]    log/log.go:117  Starting metrics logging every 30s
2020-08-22T22:30:38.043Z        INFO    instance/beat.go:402    filebeat start running.
2020-08-22T22:30:38.043Z        INFO    registrar/registrar.go:97       No registry file found under: /usr/share/filebeat/data/registry. Creating a new registry file.
2020-08-22T22:30:38.047Z        INFO    registrar/registrar.go:134      Loading registrar data from /usr/share/filebeat/data/registry
2020-08-22T22:30:38.047Z        INFO    registrar/registrar.go:141      States Loaded from registrar: 0
2020-08-22T22:30:38.047Z        WARN    beater/filebeat.go:367  Filebeat is unable to load the Ingest Node pipelines for the configured modules because the Elasticsearch output is not configured/enabled. If you have already loaded the Ingest Node pipelines or are using Logstash pipelines, you can ignore this warning.
2020-08-22T22:30:38.047Z        INFO    crawler/crawler.go:72   Loading Inputs: 1
2020-08-22T22:30:38.047Z        INFO    log/input.go:148        Configured paths: [/logs/application.log]
2020-08-22T22:30:38.047Z        INFO    input/input.go:114      Starting input of type: log; ID: 2137414975019652560
2020-08-22T22:30:38.047Z        INFO    crawler/crawler.go:106  Loading and starting Inputs completed. Enabled inputs: 1
2020-08-22T22:30:38.047Z        INFO    log/harvester.go:255    Harvester started for file: /logs/application.log
2020-08-22T22:30:38.074Z        INFO    pipeline/output.go:95   Connecting to backoff(async(tcp://logstash-service:5044))
2020-08-22T22:30:38.076Z        INFO    pipeline/output.go:105  Connection to backoff(async(tcp://logstash-service:5044)) established
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods
NAME                                 READY   STATUS    RESTARTS   AGE
esnode-0                             1/1     Running   0          92m
filebeat-llrsm                       1/1     Running   0          39s
kibana-5b78fbc78f-5qbgr              1/1     Running   0          86m
logapp-deployment-569dd8b478-mzjjv   1/1     Running   0          30h
logstash-54b9f64c7-vhstk             1/1     Running   0          45m
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs logstash-54b9f64c7-vhstk
Could not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console
[INFO ] 2020-08-22 21:48:06.034 [main] writabledirectory - Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
[INFO ] 2020-08-22 21:48:06.048 [main] writabledirectory - Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
[WARN ] 2020-08-22 21:48:06.779 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specified
[INFO ] 2020-08-22 21:48:06.790 [LogStash::Runner] runner - Starting Logstash {"logstash.version"=>"6.8.12"}
[INFO ] 2020-08-22 21:48:06.802 [LogStash::Runner] agent - No persistent UUID file found. Generating new UUID {:uuid=>"e6c5ce3f-4df5-4647-b069-6221d2f87d11", :path=>"/usr/share/logstash/data/uuid"}
[INFO ] 2020-08-22 21:48:30.848 [Converge PipelineAction::Create<main>] pipeline - Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[INFO ] 2020-08-22 21:48:34.609 [[main]-pipeline-manager] elasticsearch - Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch-cluster:9200/]}}
[WARN ] 2020-08-22 21:48:35.794 [[main]-pipeline-manager] elasticsearch - Restored connection to ES instance {:url=>"http://elasticsearch-cluster:9200/"}
[INFO ] 2020-08-22 21:48:36.456 [[main]-pipeline-manager] elasticsearch - ES Output version determined {:es_version=>6}
[WARN ] 2020-08-22 21:48:36.456 [[main]-pipeline-manager] elasticsearch - Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[INFO ] 2020-08-22 21:48:36.466 [[main]-pipeline-manager] elasticsearch - New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//elasticsearch-cluster:9200"]}
[INFO ] 2020-08-22 21:48:36.467 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Using default mapping template
[INFO ] 2020-08-22 21:48:36.470 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[INFO ] 2020-08-22 21:48:36.638 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Installing elasticsearch template to _template/logstash
[INFO ] 2020-08-22 21:48:37.004 [[main]-pipeline-manager] beats - Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[INFO ] 2020-08-22 21:48:37.026 [Converge PipelineAction::Create<main>] pipeline - Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x505397b0@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:173 sleep>"}
[INFO ] 2020-08-22 21:48:37.073 [Ruby-0-Thread-2: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/task.rb:22] agent - Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[INFO ] 2020-08-22 21:48:37.910 [Api Webserver] agent - Successfully started Logstash API endpoint {:port=>9600}
[INFO ] 2020-08-22 21:48:39.445 [[main]<beats] Server - Starting server on port: 5044
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl get pods
NAME                                 READY   STATUS    RESTARTS   AGE
esnode-0                             1/1     Running   0          92m
filebeat-llrsm                       1/1     Running   0          52s
kibana-5b78fbc78f-5qbgr              1/1     Running   0          86m
logapp-deployment-569dd8b478-mzjjv   1/1     Running   0          30h
logstash-54b9f64c7-vhstk             1/1     Running   0          45m
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs filebeat-llrsm
2020-08-22T22:30:38.031Z        INFO    instance/beat.go:611    Home path: [/usr/share/filebeat] Config path: [/usr/share/filebeat] Data path: [/usr/share/filebeat/data] Logs path: [/usr/share/filebeat/logs]
2020-08-22T22:30:38.038Z        INFO    instance/beat.go:618    Beat UUID: d5e7672e-c6e1-450c-a189-5d61774e35a4
2020-08-22T22:30:38.039Z        INFO    [seccomp]       seccomp/seccomp.go:116  Syscall filter successfully installed
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:931    Beat info       {"system_info": {"beat": {"path": {"config": "/usr/share/filebeat", "data": "/usr/share/filebeat/data", "home": "/usr/share/filebeat", "logs": "/usr/share/filebeat/logs"}, "type": "filebeat", "uuid": "d5e7672e-c6e1-450c-a189-5d61774e35a4"}}}
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:940    Build info      {"system_info": {"build": {"commit": "fdb5036adbe45aa10a03882b2245578ad17c3615", "libbeat": "6.8.12", "time": "2020-08-12T06:26:46.000Z", "version": "6.8.12"}}}
2020-08-22T22:30:38.039Z        INFO    [beat]  instance/beat.go:943    Go runtime info {"system_info": {"go": {"os":"linux","arch":"amd64","max_procs":4,"version":"go1.10.8"}}}
2020-08-22T22:30:38.041Z        INFO    [beat]  instance/beat.go:947    Host info       {"system_info": {"host": {"architecture":"x86_64","boot_time":"2020-08-22T18:46:50Z","containerized":false,"name":"filebeat-llrsm","ip":["127.0.0.1/8","10.1.0.21/16"],"kernel_version":"4.19.104-microsoft-standard","mac":["86:2d:c8:4a:5d:d3"],"os":{"family":"redhat","platform":"centos","name":"CentOS Linux","version":"7 (Core)","major":7,"minor":8,"patch":2003,"codename":"Core"},"timezone":"UTC","timezone_offset_sec":0}}}
2020-08-22T22:30:38.041Z        INFO    [beat]  instance/beat.go:976    Process info    {"system_info": {"process": {"capabilities": {"inheritable":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"permitted":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"effective":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"bounding":["chown","dac_override","fowner","fsetid","kill","setgid","setuid","setpcap","net_bind_service","net_raw","sys_chroot","mknod","audit_write","setfcap"],"ambient":null}, "cwd": "/usr/share/filebeat", "exe": "/usr/share/filebeat/filebeat", "name": "filebeat", "pid": 1, "ppid": 0, "seccomp": {"mode":"filter","no_new_privs":true}, "start_time": "2020-08-22T22:30:37.780Z"}}}
2020-08-22T22:30:38.041Z        INFO    instance/beat.go:280    Setup Beat: filebeat; Version: 6.8.12
2020-08-22T22:30:38.042Z        INFO    [publisher]     pipeline/module.go:110  Beat name: filebeat-llrsm
2020-08-22T22:30:38.043Z        INFO    [monitoring]    log/log.go:117  Starting metrics logging every 30s
2020-08-22T22:30:38.043Z        INFO    instance/beat.go:402    filebeat start running.
2020-08-22T22:30:38.043Z        INFO    registrar/registrar.go:97       No registry file found under: /usr/share/filebeat/data/registry. Creating a new registry file.
2020-08-22T22:30:38.047Z        INFO    registrar/registrar.go:134      Loading registrar data from /usr/share/filebeat/data/registry
2020-08-22T22:30:38.047Z        INFO    registrar/registrar.go:141      States Loaded from registrar: 0
2020-08-22T22:30:38.047Z        WARN    beater/filebeat.go:367  Filebeat is unable to load the Ingest Node pipelines for the configured modules because the Elasticsearch output is not configured/enabled. If you have already loaded the Ingest Node pipelines or are using Logstash pipelines, you can ignore this warning.
2020-08-22T22:30:38.047Z        INFO    crawler/crawler.go:72   Loading Inputs: 1
2020-08-22T22:30:38.047Z        INFO    log/input.go:148        Configured paths: [/logs/application.log]
2020-08-22T22:30:38.047Z        INFO    input/input.go:114      Starting input of type: log; ID: 2137414975019652560
2020-08-22T22:30:38.047Z        INFO    crawler/crawler.go:106  Loading and starting Inputs completed. Enabled inputs: 1
2020-08-22T22:30:38.047Z        INFO    log/harvester.go:255    Harvester started for file: /logs/application.log
2020-08-22T22:30:38.074Z        INFO    pipeline/output.go:95   Connecting to backoff(async(tcp://logstash-service:5044))
2020-08-22T22:30:38.076Z        INFO    pipeline/output.go:105  Connection to backoff(async(tcp://logstash-service:5044)) established
2020-08-22T22:31:08.046Z        INFO    [monitoring]    log/log.go:144  Non-zero metrics in the last 30s        {"monitoring": {"metrics": {"beat":{"cpu":{"system":{"ticks":90,"time":{"ms":92}},"total":{"ticks":210,"time":{"ms":221},"value":210},"user":{"ticks":120,"time":{"ms":129}}},"handles":{"limit":{"hard":1048576,"soft":1048576},"open":7},"info":{"ephemeral_id":"3c5df3b1-f52c-485e-baa8-33c63fa20677","uptime":{"ms":30033}},"memstats":{"gc_next":7710624,"memory_alloc":5397424,"memory_total":27758792,"rss":35766272}},"filebeat":{"events":{"added":2677,"done":2677},"harvester":{"open_files":1,"running":1,"started":1}},"libbeat":{"config":{"module":{"running":0}},"output":{"events":{"acked":2676,"batches":8,"total":2676},"read":{"bytes":54},"type":"logstash","write":{"bytes":65949}},"pipeline":{"clients":1,"events":{"active":0,"filtered":1,"published":2676,"retry":2048,"total":2677},"queue":{"acked":2676}}},"registrar":{"states":{"current":1,"update":2677},"writes":{"success":10,"total":10}},"system":{"cpu":{"cores":4},"load":{"1":1.02,"15":0.58,"5":0.66,"norm":{"1":0.255,"15":0.145,"5":0.165}}}}}}
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$ kubectl logs logstash-54b9f64c7-vhstk
Could not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console
[INFO ] 2020-08-22 21:48:06.034 [main] writabledirectory - Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
[INFO ] 2020-08-22 21:48:06.048 [main] writabledirectory - Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
[WARN ] 2020-08-22 21:48:06.779 [LogStash::Runner] multilocal - Ignoring the 'pipelines.yml' file because modules or command line options are specified
[INFO ] 2020-08-22 21:48:06.790 [LogStash::Runner] runner - Starting Logstash {"logstash.version"=>"6.8.12"}
[INFO ] 2020-08-22 21:48:06.802 [LogStash::Runner] agent - No persistent UUID file found. Generating new UUID {:uuid=>"e6c5ce3f-4df5-4647-b069-6221d2f87d11", :path=>"/usr/share/logstash/data/uuid"}
[INFO ] 2020-08-22 21:48:30.848 [Converge PipelineAction::Create<main>] pipeline - Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[INFO ] 2020-08-22 21:48:34.609 [[main]-pipeline-manager] elasticsearch - Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch-cluster:9200/]}}
[WARN ] 2020-08-22 21:48:35.794 [[main]-pipeline-manager] elasticsearch - Restored connection to ES instance {:url=>"http://elasticsearch-cluster:9200/"}
[INFO ] 2020-08-22 21:48:36.456 [[main]-pipeline-manager] elasticsearch - ES Output version determined {:es_version=>6}
[WARN ] 2020-08-22 21:48:36.456 [[main]-pipeline-manager] elasticsearch - Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[INFO ] 2020-08-22 21:48:36.466 [[main]-pipeline-manager] elasticsearch - New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//elasticsearch-cluster:9200"]}
[INFO ] 2020-08-22 21:48:36.467 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Using default mapping template
[INFO ] 2020-08-22 21:48:36.470 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[INFO ] 2020-08-22 21:48:36.638 [Ruby-0-Thread-6: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-output-elasticsearch-9.4.0-java/lib/logstash/outputs/elasticsearch/common.rb:42] elasticsearch - Installing elasticsearch template to _template/logstash
[INFO ] 2020-08-22 21:48:37.004 [[main]-pipeline-manager] beats - Beats inputs: Starting input listener {:address=>"0.0.0.0:5044"}
[INFO ] 2020-08-22 21:48:37.026 [Converge PipelineAction::Create<main>] pipeline - Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x505397b0@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:173 sleep>"}
[INFO ] 2020-08-22 21:48:37.073 [Ruby-0-Thread-2: /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/stud-0.0.23/lib/stud/task.rb:22] agent - Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[INFO ] 2020-08-22 21:48:37.910 [Api Webserver] agent - Successfully started Logstash API endpoint {:port=>9600}
[INFO ] 2020-08-22 21:48:39.445 [[main]<beats] Server - Starting server on port: 5044
avivka@DESKTOP-48MKEI0:~/LogApp/controllers$